{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5AxCtlFHGdI",
        "outputId": "4b1775ac-05da-43a3-a90d-fef850e97b30"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# add google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iw6jwl1vEFpe"
      },
      "source": [
        "# Data Cleaning\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRCfCna5Cb05",
        "outputId": "81c7bb1b-56a9-4d50-956e-cd26cabb071c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of columns dropped: 2\n"
          ]
        }
      ],
      "source": [
        "from pandas.api.types import is_numeric_dtype\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "df = pd.read_csv('/content/drive/MyDrive/dataset_clean.csv')\n",
        "num_cols_before = df.shape[1]\n",
        "df = df.drop(['Order Zipcode','Shipping Date'], axis=1)\n",
        "num_cols_after = df.shape[1]\n",
        "num_cols_dropped = num_cols_before - num_cols_after\n",
        "print(\"Number of columns dropped:\", num_cols_dropped)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFR7h6aPCrbY"
      },
      "outputs": [],
      "source": [
        "numeric_columns = [col for col in df.select_dtypes(include=np.number) if col not in df.filter(like='non_numeric')]\n",
        "numeric_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RMPLA4SICwhy",
        "outputId": "415abb1a-c4ee-4579-ed59-26fa8795c809"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Type': 'category', 'Days for shipping (real)': 'int64', 'Days for shipment (scheduled)': 'int64', 'Sales per customer': 'float64', 'Delivery Status': 'category', 'Late_delivery_risk': 'int64', 'Category Id': 'int64', 'Category Name': 'category', 'Customer City': 'category', 'Customer Country': 'category', 'Customer Fname': 'category', 'Customer Id': 'int64', 'Customer Lname': 'category', 'Customer Segment': 'category', 'Customer State': 'category', 'Customer Street': 'category', 'Customer Zipcode': 'float64', 'Department Id': 'int64', 'Department Name': 'category', 'Latitude': 'float64', 'Longitude': 'float64', 'Market': 'category', 'Order City': 'category', 'Order Country': 'category', 'Order Customer Id': 'int64', 'Order Date': 'category', 'Order Id': 'int64', 'Order Item Cardprod Id': 'int64', 'Order Item Discount': 'float64', 'Order Item Discount Rate': 'float64', 'Order Item Id': 'int64', 'Order Item Profit Ratio': 'float64', 'Order Item Quantity': 'int64', 'Sales': 'float64', 'Order Profit Per Order': 'float64', 'Order Region': 'category', 'Order State': 'category', 'Order Status': 'category', 'Product Card Id': 'int64', 'Product Category Id': 'int64', 'Product Name': 'category', 'Product Price': 'float64', 'Product Status': 'int64', 'Shipping Mode': 'category'}\n"
          ]
        }
      ],
      "source": [
        "def get_column_dtypes(df):\n",
        "  dtype_dict = {}\n",
        "  for col in df.columns:\n",
        "    # Get the data type\n",
        "    dtype = df[col].dtype\n",
        "    # Check if the data type is numeric\n",
        "    if not is_numeric_dtype(dtype):\n",
        "      dtype_dict[col] = 'category'\n",
        "    else:\n",
        "      # Remove 'dtype(' and ')' from the string representation\n",
        "      dtype = str(dtype).strip(\"dtype(')\").strip(\")\")\n",
        "      dtype_dict[col] = dtype\n",
        "  return dtype_dict\n",
        "\n",
        "\n",
        "data_types = get_column_dtypes(df)\n",
        "print(data_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ZvThBtgPElU",
        "outputId": "bf7005f6-f0ca-4b64-b239-e93201004465"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Index(['Type', 'Days for shipping (real)', 'Days for shipment (scheduled)',\n",
              "       'Sales per customer', 'Delivery Status', 'Late_delivery_risk',\n",
              "       'Category Id', 'Category Name', 'Customer City', 'Customer Country',\n",
              "       'Customer Fname', 'Customer Id', 'Customer Lname', 'Customer Segment',\n",
              "       'Customer State', 'Customer Street', 'Customer Zipcode',\n",
              "       'Department Id', 'Department Name', 'Latitude', 'Longitude', 'Market',\n",
              "       'Order City', 'Order Country', 'Order Customer Id', 'Order Date',\n",
              "       'Order Id', 'Order Item Cardprod Id', 'Order Item Discount',\n",
              "       'Order Item Discount Rate', 'Order Item Id', 'Order Item Profit Ratio',\n",
              "       'Order Item Quantity', 'Sales', 'Order Profit Per Order',\n",
              "       'Order Region', 'Order State', 'Order Status', 'Product Card Id',\n",
              "       'Product Category Id', 'Product Name', 'Product Price',\n",
              "       'Product Status', 'Shipping Mode'],\n",
              "      dtype='object')"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-mRKaWMC1yX"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv('/content/drive/MyDrive/dataset_clean.csv', delimiter=',', dtype=data_types)\n",
        "\n",
        "numerical_features = numeric_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJ3SD1aNPOQi"
      },
      "outputs": [],
      "source": [
        "columns_to_drop = ['Department Name', 'Latitude', 'Longitude','Customer Zipcode','Type','Product Category Id','Customer State', 'Customer Street','Product Status','Order Zipcode','Shipping Date']\n",
        "data = data.drop(columns=columns_to_drop)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AyEUexU_QtqL"
      },
      "outputs": [],
      "source": [
        "# truncuate data to 100000 rows\n",
        "data = data.head(100000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o7DVcTgMRVDz",
        "outputId": "597f301f-0a48-4ce3-878b-288b323b863e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Days for shipping (real)',\n",
              " 'Days for shipment (scheduled)',\n",
              " 'Sales per customer',\n",
              " 'Late_delivery_risk',\n",
              " 'Category Id',\n",
              " 'Customer Id',\n",
              " 'Department Id',\n",
              " 'Order Customer Id',\n",
              " 'Order Id',\n",
              " 'Order Item Cardprod Id',\n",
              " 'Order Item Discount',\n",
              " 'Order Item Discount Rate',\n",
              " 'Order Item Id',\n",
              " 'Order Item Profit Ratio',\n",
              " 'Order Item Quantity',\n",
              " 'Sales',\n",
              " 'Order Profit Per Order',\n",
              " 'Product Card Id',\n",
              " 'Product Price']"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# create a dictionary with numerical features and as keys get their types from data_types\n",
        "numeric_columns = [col for col in data.select_dtypes(include=np.number) if col not in data.filter(like='non_numeric')]\n",
        "numeric_columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6IxMlWfUDtu",
        "outputId": "dbc9c8dc-0f95-4267-bf52-5344c28b07b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Days for shipping (real) 0\n",
            "Days for shipment (scheduled) 0\n",
            "Sales per customer 0\n",
            "Delivery Status 0\n",
            "Late_delivery_risk 0\n",
            "Category Id 0\n",
            "Category Name 0\n",
            "Customer City 0\n",
            "Customer Country 0\n",
            "Customer Fname 0\n",
            "Customer Id 0\n",
            "Customer Lname 0\n",
            "Customer Segment 0\n",
            "Department Id 0\n",
            "Market 0\n",
            "Order City 0\n",
            "Order Country 0\n",
            "Order Customer Id 0\n",
            "Order Date 0\n",
            "Order Id 0\n",
            "Order Item Cardprod Id 0\n",
            "Order Item Discount 0\n",
            "Order Item Discount Rate 0\n",
            "Order Item Id 0\n",
            "Order Item Profit Ratio 0\n",
            "Order Item Quantity 0\n",
            "Sales 0\n",
            "Order Profit Per Order 0\n",
            "Order Region 0\n",
            "Order State 0\n",
            "Order Status 0\n",
            "Product Card Id 0\n",
            "Product Name 0\n",
            "Product Price 0\n",
            "Shipping Mode 0\n"
          ]
        }
      ],
      "source": [
        "# print which column contains how many nan values\n",
        "for col in data.columns:\n",
        "  print(col, data[col].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-wo5jElTWfc",
        "outputId": "27c79586-0a42-4e64-e1f8-b209d2233516"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before dropping null values: (20000, 35)\n",
            "After dropping null values: (20000, 35)\n"
          ]
        }
      ],
      "source": [
        "# print row count before and after dropping null\n",
        "print(\"Before dropping null values:\", data.shape)\n",
        "data = data.dropna()\n",
        "print(\"After dropping null values:\", data.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-kSkxSh8EJ4L"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9EgWTZSuEVAp"
      },
      "source": [
        "# Feature Selection\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ZJq1pD1Euu_"
      },
      "outputs": [],
      "source": [
        "# Select the features and target variable\n",
        "X = data.drop(['Category Name'], axis=1)  # Exclude the 'Category Name' column\n",
        "X = pd.get_dummies(X)\n",
        "y = data['Category Name']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U_AtRf2QTGx-",
        "outputId": "919f722b-2679-443f-dd72-eaede5a7ac5d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X shape: (20000, 34)\n",
            "y shape: (20000,)\n"
          ]
        }
      ],
      "source": [
        "# print row counts\n",
        "print(\"X shape:\", X.shape)\n",
        "print(\"y shape:\", y.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnRoIE1YEYHU"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "# Train a Random Forest classifier\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Retrieve feature importance scores\n",
        "feature_importances = model.feature_importances_\n",
        "\n",
        "# Create a dataframe with feature names and importance scores\n",
        "feature_importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the dataframe by importance scores in descending order\n",
        "feature_importances_df = feature_importances_df.sort_values('Importance', ascending=False)\n",
        "\n",
        "# Select the top-k features (e.g., top 10)\n",
        "k = 5\n",
        "selected_features = feature_importances_df.head(k)['Feature'].tolist()\n",
        "\n",
        "# Subset the X dataframe with the selected features\n",
        "X_selected = X[selected_features]\n",
        "\n",
        "# Print the selected features\n",
        "print(\"Selected Features:\")\n",
        "print(X_selected.columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LeWgaVLECzni"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_selection import mutual_info_classif\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import time\n",
        "# Identify categorical and numerical columns\n",
        "categorical_cols = data.select_dtypes(include=['object', 'category']).columns\n",
        "numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns\n",
        "\n",
        "# Preprocessing for numerical data\n",
        "numerical_transformer = Pipeline(steps=[\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "# Preprocessing for categorical data\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine preprocessing steps\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_cols),\n",
        "        ('cat', categorical_transformer, categorical_cols)\n",
        "    ])\n",
        "\n",
        "# Apply preprocessing\n",
        "X_preprocessed = preprocessor.fit_transform(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PUFbvxyVD6GK"
      },
      "outputs": [],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Calculate information gain (mutual information) for each feature\n",
        "info_gain = mutual_info_classif(X_preprocessed, y)\n",
        "\n",
        "end_time = time.time()\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")\n",
        "\n",
        "# Retrieve feature names after one-hot encoding\n",
        "feature_names = (numerical_cols.tolist() +\n",
        "                 preprocessor.named_transformers_['cat']['onehot'].get_feature_names_out(categorical_cols).tolist())\n",
        "\n",
        "# Create a dataframe with feature names and information gain scores\n",
        "feature_info_gain_df = pd.DataFrame({'Feature': feature_names, 'Information_Gain': info_gain})\n",
        "\n",
        "# Sort the dataframe by information gain scores in descending order\n",
        "feature_info_gain_df = feature_info_gain_df.sort_values('Information_Gain', ascending=False)\n",
        "\n",
        "# Select the top-k features (e.g., top 5)\n",
        "k = 10\n",
        "selected_features = feature_info_gain_df.head(k)['Feature'].tolist()\n",
        "selected_features\n",
        "# Since selected_features are transformed feature names, we can't directly subset X with them.\n",
        "# For practical purposes, you might need to map these back to original features or just use these top features for your model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hmpu8GzGhYf",
        "outputId": "9bec7e9d-5860-46f7-b29c-5328d50098c1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Order Item Cardprod Id',\n",
              " 'Category Id',\n",
              " 'Product Card Id',\n",
              " 'Order Item Id',\n",
              " 'Product Price']"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "k = 5\n",
        "selected_features = feature_info_gain_df.head(k)['Feature'].tolist()\n",
        "selected_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lHannKovNJN5"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_selection import RFE\n",
        "\n",
        "# # Select the features and target variable\n",
        "# X = data.drop(['URGENCY'], axis=1)  # Exclude the 'URGENCY' column\n",
        "# y = data['URGENCY']\n",
        "\n",
        "# # Perform one-hot encoding on categorical variables\n",
        "# X_encoded = pd.get_dummies(X)\n",
        "\n",
        "# Create a base model (e.g., Random Forest)\n",
        "model = RandomForestClassifier()\n",
        "\n",
        "# Perform Recursive Feature Elimination (RFE)\n",
        "rfe = RFE(estimator=model, n_features_to_select=5)\n",
        "X_selected = rfe.fit_transform(X, y)\n",
        "\n",
        "# Get the selected feature names\n",
        "selected_feature_names = X.columns[rfe.support_]\n",
        "\n",
        "# Print the selected feature names\n",
        "print(\"Selected Features:\")\n",
        "print(selected_feature_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsEeCjexN3G5"
      },
      "source": [
        "# Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbIli4WTN5d0"
      },
      "outputs": [],
      "source": [
        "def take_average(res: list, algorithm_name: str):\n",
        "    avg_accuracy, avg_precision, avg_recall, avg_f1 = 0, 0, 0, 0\n",
        "    avg_f1_micro, avg_f1_macro = 0, 0\n",
        "    for acc, prec, rec, f1, f1_micro, f1_macro in res:\n",
        "        avg_accuracy += acc\n",
        "        avg_precision += prec\n",
        "        avg_recall += rec\n",
        "        avg_f1 += f1\n",
        "        avg_f1_micro += f1_micro\n",
        "        avg_f1_macro += f1_macro\n",
        "\n",
        "    avg_accuracy = avg_accuracy / len(res)\n",
        "    avg_precision = avg_precision / len(res)\n",
        "    avg_recall = avg_recall / len(res)\n",
        "    avg_f1 = avg_f1 / len(res)\n",
        "    avg_f1_micro = avg_f1_micro / len(res)\n",
        "    avg_f1_macro = avg_f1_macro / len(res)\n",
        "\n",
        "    print(f\"Average Metrics for {algorithm_name}\")\n",
        "    print(f\"Accuracy {avg_accuracy}\")\n",
        "    print(f\"Precision {avg_precision}\")\n",
        "    print(f\"Recall {avg_recall}\")\n",
        "    print(f\"F1 {avg_f1}\\n\")\n",
        "    print(f\"F1-micro {avg_f1_micro}\\n\")\n",
        "    print(f\"F1-macro {avg_f1_macro}\\n\")\n",
        "\n",
        "    val_dict[algorithm_name] = [avg_accuracy, avg_precision, avg_recall, avg_f1, avg_f1_micro, avg_f1_macro]\n",
        "\n",
        "def print_confusion_matrix(metrics_cv: list, all_y_tests: list, all_y_preds: list, algorithm_name: str):\n",
        "    # finds best result based on f1 metric\n",
        "    f1_index = 3\n",
        "    f1_results = list(map(lambda m: m[f1_index], metrics_cv))\n",
        "    best_metric_index = f1_results.index(max(f1_results))\n",
        "\n",
        "    y_test = all_y_tests[best_metric_index]\n",
        "    y_pred = all_y_preds[best_metric_index]\n",
        "\n",
        "    print(f\"Best Metric based on F1 for {algorithm_name}\")\n",
        "    print(f\"Accuracy {metrics_cv[best_metric_index][0]}\")\n",
        "    print(f\"Precision {metrics_cv[best_metric_index][1]}\")\n",
        "    print(f\"Recall {metrics_cv[best_metric_index][2]}\")\n",
        "    print(f\"F1 {metrics_cv[best_metric_index][3]}\\n\")\n",
        "    print(f\"F1-micro {metrics_cv[best_metric_index][4]}\\n\")\n",
        "    print(f\"F1-macro {metrics_cv[best_metric_index][5]}\\n\")\n",
        "\n",
        "    print(f\"Confusion Matrix {algorithm_name}\")\n",
        "    print(confusion_matrix(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2eGx2pjHN_Bv"
      },
      "source": [
        "# SVM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eionze6cOC9P"
      },
      "outputs": [],
      "source": [
        "def svm(X, y):\n",
        "    svm = SVC()\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42    )\n",
        "    metrics_cv = []\n",
        "    all_y_tests = []\n",
        "    all_y_preds = []\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        svm.fit(X_train, y_train)\n",
        "        y_pred = svm.predict(X_test)\n",
        "\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "\n",
        "        all_y_tests.append(y_test)\n",
        "        all_y_preds.append(y_pred)\n",
        "\n",
        "        metrics_cv.append([accuracy, precision, recall, f1, f1_micro, f1_macro])\n",
        "    return metrics_cv, all_y_tests, all_y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMU8_XWdOKOZ"
      },
      "source": [
        "# Stochastic Gradient Descent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "484JRYRwONYM"
      },
      "outputs": [],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "def sgd(X, y):\n",
        "    sgd = SGDClassifier()\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    metrics_cv = []\n",
        "\n",
        "    all_y_tests = []\n",
        "    all_y_preds = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        sgd.fit(X_train, y_train)\n",
        "        y_pred = sgd.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "        metrics_cv.append([accuracy, precision, recall, f1, f1_micro, f1_macro])\n",
        "        all_y_tests.append(y_test)\n",
        "        all_y_preds.append(y_pred)\n",
        "\n",
        "    return metrics_cv, all_y_tests, all_y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBgPe1euORLn"
      },
      "source": [
        "# Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uoOPjB99OSld"
      },
      "outputs": [],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def decision_tree(X, y):\n",
        "    dt = DecisionTreeClassifier()\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    metrics_cv = []\n",
        "    all_y_preds = []\n",
        "    all_y_tests = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        dt.fit(X_train, y_train)\n",
        "        y_pred = dt.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "        metrics_cv.append([accuracy, precision, recall, f1, f1_micro, f1_macro])\n",
        "        all_y_tests.append(y_test)\n",
        "        all_y_preds.append(y_pred)\n",
        "\n",
        "    return metrics_cv, all_y_tests, all_y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hVP_lnEOYYS"
      },
      "source": [
        "# Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52MTBgOiOaCf"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "def naive_bayes(X, y):\n",
        "    nb = GaussianNB()\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    metrics_cv = []\n",
        "\n",
        "    all_y_preds = []\n",
        "    all_y_tests = []\n",
        "\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        nb.fit(X_train, y_train)\n",
        "        y_pred = nb.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "        metrics_cv.append([accuracy, precision, recall, f1, f1_micro, f1_macro])\n",
        "        all_y_preds.append(y_pred)\n",
        "        all_y_tests.append(y_test)\n",
        "\n",
        "    return metrics_cv, all_y_tests, all_y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyCQ_B2LOeow"
      },
      "source": [
        "# Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dViusz2-OgcW"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "def random_forest(X, y):\n",
        "    nn = RandomForestClassifier()\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    metrics_cv = []\n",
        "\n",
        "    all_y_preds = []\n",
        "    all_y_tests = []\n",
        "\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        nn.fit(X_train, y_train)\n",
        "        y_pred = nn.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "        metrics_cv.append([accuracy, precision, recall, f1, f1_micro, f1_macro])\n",
        "\n",
        "        all_y_preds.append(y_pred)\n",
        "        all_y_tests.append(y_test)\n",
        "\n",
        "    return metrics_cv, all_y_tests, all_y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9sf1doPOj6Y"
      },
      "source": [
        "#Multi-Layer Perceptron"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_HxsTg1oOoLU"
      },
      "outputs": [],
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "def mlp(X, y):\n",
        "    nn = MLPClassifier(hidden_layer_sizes=(5, 2), max_iter=500)\n",
        "\n",
        "    skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "    metrics_cv = []\n",
        "\n",
        "    all_y_preds = []\n",
        "    all_y_tests = []\n",
        "\n",
        "    for train_index, test_index in skf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
        "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
        "\n",
        "        nn.fit(X_train, y_train)\n",
        "        y_pred = nn.predict(X_test)\n",
        "\n",
        "        accuracy = accuracy_score(y_test, y_pred)\n",
        "        precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
        "        f1_micro = f1_score(y_test, y_pred, average='micro', zero_division=0)\n",
        "        f1_macro = f1_score(y_test, y_pred, average='macro', zero_division=0)\n",
        "\n",
        "        metrics_cv.append([accuracy, precision, recall, f1, f1_micro, f1_macro])\n",
        "\n",
        "        all_y_preds.append(y_pred)\n",
        "        all_y_tests.append(y_test)\n",
        "\n",
        "    return metrics_cv, all_y_tests, all_y_preds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzfAYBKQO6XF"
      },
      "source": [
        "# Experiment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NpWnKJXbO7d9"
      },
      "outputs": [],
      "source": [
        "for i in range(len(selected_features)):\n",
        "    X_selected = X[selected_features[i]]\n",
        "    print(f\"Feature Set #{i}\")\n",
        "    print(selected_features[i])\n",
        "    results = [svm(X_selected, y), sgd(X_selected, y), decision_tree(X_selected, y), naive_bayes(X_selected, y), random_forest(X_selected, y), mlp(X_selected, y)]\n",
        "    names = [\"Support Vector Machine\", \"Stochastic Gradient Descent\", \"Decision Tree\", \"Naive Bayes\", \"Random Forest\", \"Multi-Layer Perceptron\"]\n",
        "    j = 0\n",
        "    np.save(f\"results_f{i}.npy\", [row[0] for row in results])\n",
        "   # with open('results.json', 'w') as f:\n",
        "     # json.dump([result.tolist() for result in results], f)\n",
        "    for metrics_cv, all_y_tests, all_y_preds in results:\n",
        "        neural_network_result = take_average(metrics_cv, names[j])\n",
        "        print_confusion_matrix(metrics_cv, all_y_tests, all_y_preds, names[j])\n",
        "        j += 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMNZU3GUWOY-"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import ttest_ind\n",
        "results = np.load(\"results_f0.npy\", allow_pickle=True)\n",
        "d = dict(enumerate(results.flatten(), 1))\n",
        "print(results)\n",
        "\n",
        "# names = [\"Support Vector Machine\", \"Stochastic Gradient Descent\", \"Decision Tree\", \"Naive Bayes\", \"Random Forest\", \"Multi-Layer Perceptron\"]\n",
        "# best models: 4 and 2\n",
        "# Perform the t-test\n",
        "t_statistic, p_value = ttest_ind(results[4].flatten(), results[2].flatten())\n",
        "\n",
        "# Display the results\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "\n",
        "def f1_bar_chart_best(results):\n",
        "    algorithms = [\"Support Vector Machine\", \"Stochastic Gradient Descent\", \"Decision Tree\", \"Naive Bayes\", \"Random Forest\", \"Multi-Layer Perceptron\"]\n",
        "    values = [value[3][3] for value in results]  # Extract the fourth value from each key-value pair\n",
        "    print(values)\n",
        "\n",
        "    num_bars = len(results)\n",
        "\n",
        "    # Create an array of indices for the bars\n",
        "    indices = np.arange(num_bars)\n",
        "\n",
        "    # Set the width of each bar\n",
        "    bar_width = 0.5\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))  # Set the figure size\n",
        "\n",
        "    # Generate a list of colors using the 'tab10' colormap\n",
        "    colors = plt.cm.tab10(np.arange(num_bars))\n",
        "\n",
        "    # Plot the bars with tab10 colors\n",
        "    ax.bar(indices, values, width=bar_width, color=colors)\n",
        "\n",
        "    # Set the x-axis ticks and labels\n",
        "    ax.set_xticks(indices)\n",
        "    ax.set_xticklabels(algorithms, rotation='vertical')  # Rotate x tick labels vertically\n",
        "\n",
        "    # Set the y-axis label\n",
        "    ax.set_ylabel('Values')\n",
        "\n",
        "    # Set the plot title\n",
        "    ax.set_title('F1 Scores (Feature Set I)')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "f1_bar_chart_best(results)\n",
        "\n",
        "def plot_chart_best(data_dict):\n",
        "    algorithms = [\"Support Vector Machine\", \"Stochastic Gradient Descent\", \"Decision Tree\", \"Naive Bayes\", \"Random Forest\", \"Multi-Layer Perceptron\"]\n",
        "    values = [value[3] for value in results]  # Extract the fourth value from each key-value pair\n",
        "    #values = list(data_dict.values())\n",
        "\n",
        "    legend_names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "\n",
        "    num_bars = len(algorithms)\n",
        "    num_values = len(values[0])\n",
        "\n",
        "    # Create an array of indices for the bars\n",
        "    indices = np.arange(num_bars)\n",
        "\n",
        "    # Set the width of each bar\n",
        "    bar_width = 0.07\n",
        "\n",
        "    # Set the spacing between bars\n",
        "    spacing = 0.05\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    for i in range(num_values):\n",
        "        # Calculate the x-coordinate for each group of bars\n",
        "        x = indices + i * (bar_width + spacing)\n",
        "\n",
        "        # Extract the values for the current iteration\n",
        "        y = [value[i] for value in values]\n",
        "\n",
        "        # Plot the bars\n",
        "        ax.bar(x, y, width=bar_width)\n",
        "\n",
        "    # Set the x-axis ticks and labels\n",
        "    ax.set_xticks(indices + (bar_width * num_values + spacing * (num_values - 1)) / 2)\n",
        "    ax.set_xticklabels(algorithms, rotation='vertical')\n",
        "\n",
        "    # Set the y-axis label\n",
        "    ax.set_ylabel('Values')\n",
        "\n",
        "    # Set the plot title\n",
        "    ax.set_title('All Metrics per Model')\n",
        "\n",
        "    # Display the legend\n",
        "    ax.legend(legend_names)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "plot_chart_best(results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dswPpwQWSLg"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "def plot_bar_chart(data_dict):\n",
        "    algorithms = list(data_dict.keys())\n",
        "    values = list(data_dict.values())\n",
        "\n",
        "    legend_names = ['Accuracy', 'Precision', 'Recall', 'F1']\n",
        "\n",
        "    num_bars = len(algorithms)\n",
        "    num_values = len(values[0])\n",
        "\n",
        "    # Create an array of indices for the bars\n",
        "    indices = np.arange(num_bars)\n",
        "\n",
        "    # Set the width of each bar\n",
        "    bar_width = 0.07\n",
        "\n",
        "    # Set the spacing between bars\n",
        "    spacing = 0.05\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))\n",
        "\n",
        "    for i in range(num_values):\n",
        "        # Calculate the x-coordinate for each group of bars\n",
        "        x = indices + i * (bar_width + spacing)\n",
        "\n",
        "        # Extract the values for the current iteration\n",
        "        y = [value[i] for value in values]\n",
        "\n",
        "        # Plot the bars\n",
        "        ax.bar(x, y, width=bar_width)\n",
        "\n",
        "    # Set the x-axis ticks and labels\n",
        "    ax.set_xticks(indices + (bar_width * num_values + spacing * (num_values - 1)) / 2)\n",
        "    ax.set_xticklabels(algorithms, rotation='vertical')\n",
        "\n",
        "    # Set the y-axis label\n",
        "    ax.set_ylabel('Values')\n",
        "\n",
        "    # Set the plot title\n",
        "    ax.set_title('All Metrics per Model')\n",
        "\n",
        "    # Display the legend\n",
        "    ax.legend(legend_names)\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()\n",
        "\n",
        "def f1_bar_chart(data_dict):\n",
        "    algorithms = list(data_dict.keys())\n",
        "    values = [value[3] for value in data_dict.values()]  # Extract the fourth value from each key-value pair\n",
        "\n",
        "    num_bars = len(algorithms)\n",
        "\n",
        "    # Create an array of indices for the bars\n",
        "    indices = np.arange(num_bars)\n",
        "\n",
        "    # Set the width of each bar\n",
        "    bar_width = 0.5\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 8))  # Set the figure size\n",
        "\n",
        "    # Generate a list of colors using the 'tab10' colormap\n",
        "    colors = plt.cm.tab10(np.arange(num_bars))\n",
        "\n",
        "    # Plot the bars with tab10 colors\n",
        "    ax.bar(indices, values, width=bar_width, color=colors)\n",
        "\n",
        "    # Set the x-axis ticks and labels\n",
        "    ax.set_xticks(indices)\n",
        "    ax.set_xticklabels(algorithms, rotation='vertical')  # Rotate x tick labels vertically\n",
        "\n",
        "    # Set the y-axis label\n",
        "    ax.set_ylabel('Values')\n",
        "\n",
        "    # Set the plot title\n",
        "    ax.set_title('F1 scores Bar Plot')\n",
        "\n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bq-p8HQWVHn"
      },
      "outputs": [],
      "source": [
        "plot_bar_chart(val_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UG9MHq_FWVav"
      },
      "outputs": [],
      "source": [
        "f1_bar_chart(val_dict)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
